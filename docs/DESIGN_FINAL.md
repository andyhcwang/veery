# VoiceFlow â€” Finalized Design (Post-Review)

## Design Decisions (from 3-agent review)

### Architecture
- **Threading**: Main (rumps) + Audio (sounddevice callback) + Worker (per-utterance daemon)
- **No asyncio** â€” fights rumps for main thread event loop
- **State transitions** must use `threading.Lock` (not just buffer lock)

### State Machine (expanded)
```
IDLE â†’ RECORDING          (hotkey press)
RECORDING â†’ PROCESSING    (silence detected after speech)
RECORDING â†’ IDLE          (hotkey press = cancel, OR timeout with no speech)
PROCESSING â†’ IDLE         (success: paste text)
PROCESSING â†’ IDLE         (error: show notification)
```
- Hotkey during PROCESSING: **ignore** (simplest for v1)
- Max recording duration: 30s timeout â†’ auto-stop

### ML Pipeline
| Component | Choice | RAM | Latency |
|-----------|--------|-----|---------|
| VAD | Silero VAD v5 (ONNX) | ~50MB | <1ms |
| STT | SenseVoice-Small via FunASR | ~500MB | 300-400ms (CPU) |
| Jargon | rapidfuzz + YAML dicts | ~10MB | <1ms |
| Grammar | **Qwen3-1.7B-Instruct-4bit** via MLX | ~1GB | 50-80ms |
| **Total** | | **~1.6GB** | **350-500ms** |

### Key Changes from Original Plan
1. **Grammar model**: Qwen2.5-3B â†’ **Qwen3-1.7B-4bit** (saves 1GB, sufficient for grammar)
2. **Output**: pyperclip+pyautogui â†’ **CGEvent typing** (no clipboard corruption)
3. **STT input**: Temp WAV file â†’ **numpy array directly** to FunASR
4. **Model loading**: All eager â†’ **VAD+STT eager, grammar lazy**
5. **Latency budget**: 200-350ms â†’ **350-500ms** (realistic CPU inference)

### Output Mechanism (redesigned)
- **Short text (<500 chars)**: CGEvent typing via PyObjC â€” bypasses clipboard entirely
- **Long text (â‰¥500 chars)**: NSPasteboard-aware clipboard paste (saves ALL pasteboard types, not just plain text)
- **No pyperclip, no pyautogui** â€” both replaced by PyObjC

### Permission Handling
1. Startup: Check `AXIsProcessTrusted()` via PyObjC
2. If false: Show notification + open System Settings Accessibility pane
3. Microphone: Handled automatically by sounddevice (system dialog)
4. Input Monitoring: Document in README (not detectable programmatically)
5. Add "Test Hotkey" menu item for self-diagnosis

### Fallback Chain
```
Full:     STT â†’ Jargon â†’ Grammar â†’ Output
Degraded: STT â†’ Jargon â†’ Output          (if grammar model fails/not loaded)
Error:    Show notification                (if STT fails)
Fatal:    Show permission notification     (if audio/hotkey fails)
```

### Audio Lifecycle
- `InputStream.start()` on hotkey press (IDLE â†’ RECORDING)
- `InputStream.stop()` on speech end or cancel (â†’ IDLE)
- Stream is NOT kept open while idle (saves battery, allows sleep)

### Dependencies (revised)
Core: sounddevice, numpy, torch, funasr, onnxruntime (silero-vad), mlx, mlx-lm
App: rumps, pynput, pyobjc-framework-Cocoa, pyobjc-framework-Quartz, pyyaml, rapidfuzz
Dev: pytest, ruff

Removed: pyperclip, pyautogui
Added: pyobjc-framework-Cocoa, pyobjc-framework-Quartz, onnxruntime
Changed: Qwen2.5-3B â†’ Qwen3-1.7B

### Menubar Icons
- v1: Emoji (ðŸŽ¤, ðŸ”´, â³) â€” works with rumps title
- v2: PNG template images (18x18 @1x, 36x36 @2x) for polish

### Config
- Hotkey configurable via config.yaml (default: Cmd+Shift+Space)
- Document bilingual keyboard conflict (Cmd+Shift+Space may be input source switch)
